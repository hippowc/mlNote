这一节涉及优化算法。生活中很多问题是关于优化的问题：譬如如何在最短时间从a点到b点？如何设计一个引擎用最少的燃料提供最大的马力？

回归是做什么：有一堆数据，我们使用这些数据构造一个方程来进行分类。regression的意思是我们要选出一个最合适的参数，然后我们要使用优化算法找出最合适的参数
逻辑回归中【逻辑】指的是结果中只有两种可能，针对是与否的问题

pros：计算开销小，易实现，knowledge容易理解
cons：较低准确率

Heaviside step function或者叫 step function 跃阶函数，特点从0到1的变化非常快。
另一种从0到1也很快，但是可以很好解决。叫做sigmoid,s型函数：O(z) = 1 / (1 + e的-z次方)，长这样：
![sigmoid](image/sigmoid-1.jpg)

使用优化方法找到最佳的回归系数，regression coefficients
关于sigmoid的输入 z = w0x0 + w1x1 + w2x2+ ... + wnxn，这一串相加的因式记做：wTx, x是我们的输入数据，然后我们需要找到best coefficients w.
使用梯度上升法(gradient ascent)寻找这个系数w

额，关于为什么使用sigmoid函数，目前粗浅的理解是这样：对于任意一个实例，我们将他的所有feature代入这个方程，都可以得到一个在0-1之间的结果。如果仅仅是为了归一化而使用这个模型，其实说不通。但是书中也没有详细解释，先跳过。
